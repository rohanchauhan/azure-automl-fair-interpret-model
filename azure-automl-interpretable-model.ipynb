{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training an Azure AutoML model with Explanations\r\n",
        "We are using credit risk modelling dataset from Kaggle for the task. In this project, we train an AutoML model using Azure AutoML and after selecting the model,\r\n",
        " we assess it's fairness and interpretablity."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install Required Packages"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azureml-explain-model azureml-interpret azureml-sdk"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get Data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Datastore, Dataset\r\n",
        "\r\n",
        "# Get Workspace\r\n",
        "ws = Workspace.from_config()\r\n",
        "\r\n",
        "# Datastore Params\r\n",
        "datastore_name = 'rohands'\r\n",
        "storage_account_name = 'rohansa'\r\n",
        "container_name ='rohan-blob'\r\n",
        "# account_key = Add your account key for storage account\r\n",
        "\r\n",
        "# Get Datastore otherwise create new datastore and register blob storage\r\n",
        "if datastore_name in ws.datastores:\r\n",
        "    blob_ds = Datastore.get(ws, datastore_name=datastore_name)\r\n",
        "else:\r\n",
        "    try:\r\n",
        "        blob_ds = Datastore.register_azure_blob_container(\r\n",
        "            workspace=ws,\r\n",
        "            datastore_name=datastore_name,\r\n",
        "            account_name=storage_account_name,\r\n",
        "            #account_key = account_key\r\n",
        "            container_name=container_name\r\n",
        "        )\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)\r\n",
        "\r\n",
        "# Set as Default Datastore\r\n",
        "default_ds = ws.set_default_datastore(datastore_name)\r\n",
        "default_ds = ws.get_default_datastore()\r\n",
        "\r\n",
        "# Get Dataset otherise create new dataset and register\r\n",
        "dataset_name = 'credit risk dataset'\r\n",
        "\r\n",
        "if dataset_name not in ws.datasets:\r\n",
        "    default_ds.upload_files(\r\n",
        "        files=['./data/credit_risk_dataset.csv'],\r\n",
        "        target_path='credit-risk-data/',\r\n",
        "        overwrite=True,\r\n",
        "        show_progress=True)\r\n",
        "    \r\n",
        "    tab_dataset = Dataset.Tabular.from_delimited_files(\r\n",
        "        path=(default_ds,'credit-risk-data/*.csv'))\r\n",
        "        \r\n",
        "    try:\r\n",
        "        tab_dataset = tab_dataset.register(workspace=ws, \r\n",
        "                                name=dataset_name,\r\n",
        "                                description='credit risk data from Kaggle',\r\n",
        "                                tags = {'format':'CSV'},\r\n",
        "                                create_new_version=True)\r\n",
        "        print('Dataset registered.')\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)\r\n",
        "else:\r\n",
        "    tab_dataset = Dataset.get_by_name(ws, dataset_name)\r\n",
        "    print('Dataset already registered.')\r\n",
        "\r\n",
        "train_ds, test_ds = tab_dataset.random_split(percentage=0.7, seed=999)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625637110772
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Compute Target"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "# Compute params\r\n",
        "compute_name = 'rohan-vm-cluster'\r\n",
        "training_cluster = None\r\n",
        "\r\n",
        "if compute_name in ws.compute_targets:\r\n",
        "    training_cluster = ComputeTarget(ws, compute_name)\r\n",
        "    print(\"Using existing cluster.\")\r\n",
        "else:\r\n",
        "    try:\r\n",
        "        compute_config = AmlCompute.provisioning_configuration(\r\n",
        "            vm_size ='STANDARD_DS11_V2', \r\n",
        "            max_nodes=2 )\r\n",
        "        training_cluster = ComputeTarget.create(ws, compute_name, compute_config)\r\n",
        "        training_cluster.wait_for_completion(show_output=True)\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)\r\n",
        "    print(\"Cluster created.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625637112108
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Configure and Run AML"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Configuration\n",
        "automl_config = AutoMLConfig(name='Automated Credit Risk Modelling',\n",
        "                             task='classification',\n",
        "                             compute_target=training_cluster,\n",
        "                             training_data = train_ds,\n",
        "                             validation_data = test_ds,\n",
        "                             label_column_name='loan_status',\n",
        "                             iterations=10,\n",
        "                             primary_metric = 'AUC_weighted',\n",
        "                             max_concurrent_iterations=2,\n",
        "                             featurization='auto'\n",
        "                             )\n",
        "\n",
        "\n",
        "# Run the Experiment\n",
        "automl_experiment = Experiment(ws, 'azure-automl-fair-interpret-model')\n",
        "automl_run = automl_experiment.submit(automl_config)\n",
        "RunDetails(automl_run).show()\n",
        "automl_run.wait_for_completion()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625637911387
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Get Best Run"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run, fitted_model = automl_run.get_output()\r\n",
        "print(best_run)\r\n",
        "\r\n",
        "print('\\nBest Model Definition:')\r\n",
        "print(fitted_model)\r\n",
        "\r\n",
        "print('\\nBest Run Transformations:')\r\n",
        "for step in fitted_model.named_steps:\r\n",
        "    print(step)\r\n",
        "    \r\n",
        "print('\\nBest Run Metrics:')\r\n",
        "best_run_metrics = best_run.get_metrics()\r\n",
        "for metric_name in best_run_metrics:\r\n",
        "    metric = best_run_metrics[metric_name]\r\n",
        "    print(metric_name, metric)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625637920694
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explain Model using PFI Explainer and Get Global Feature Importance Values"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from interpret.ext.blackbox import PFIExplainer\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "df = tab_dataset.to_pandas_dataframe()\r\n",
        "features = list(df.columns).remove('loan_status')\r\n",
        "classes = df.loan_status.unique()\r\n",
        "\r\n",
        "X_train = train_ds.to_pandas_dataframe().drop('loan_status', axis=1)\r\n",
        "y_train = train_ds.to_pandas_dataframe().loan_status\r\n",
        "\r\n",
        "X_test = test_ds.to_pandas_dataframe().drop('loan_status', axis=1)\r\n",
        "y_test = test_ds.to_pandas_dataframe().loan_status\r\n",
        "\r\n",
        "pfi_explainer = PFIExplainer(model=fitted_model,\r\n",
        " features=features,\r\n",
        " classes=classes)\r\n",
        "\r\n",
        "# PFIExplainer\r\n",
        "global_explanation = pfi_explainer.explain_global(X_train, y_train)\r\n",
        "global_feature_importance = global_explanation.get_feature_importance_dict()\r\n",
        "\r\n",
        "# Figure\r\n",
        "fig = plt.figure(figsize=(15,5))\r\n",
        "top_n = 5 #len(global_feature_importance)\r\n",
        "plt.bar(range(top_n), list(global_feature_importance.values())[:top_n], align='center')\r\n",
        "plt.xticks(range(top_n), list(global_feature_importance.keys())[:top_n], rotation=15)\r\n",
        "plt.tick_params(labelsize=18)\r\n",
        "\r\n",
        "plt.title(\"Top {} Features\".format(top_n), fontsize=24)\r\n",
        "plt.xlabel(\"Features\", fontsize=22)\r\n",
        "plt.ylabel(\"Feature Importance\", fontsize=22)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625637940749
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Register the Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Register model\r\n",
        "best_run.register_model(model_path='outputs/model.pkl', model_name='credit_risk_model',\r\n",
        "    tags={'Training context':'Auto ML Credit Risk Model'},\r\n",
        "    properties={'AUC': best_run_metrics['AUC_weighted'], 'Accuracy': best_run_metrics['accuracy']})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625637941711
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}